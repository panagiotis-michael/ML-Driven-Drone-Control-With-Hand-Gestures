# ML-Driven Drone Control With Hand Gestures
> Explore machine learning by building a CNN image classification model using Keras, and control a drone with hand gestures

## Table of Contents
* [General Info](#general-information)
* [Technologies Used](#technologies-used)
* [Features](#features)
* [Setup](#setup)
* [Project Status](#project-status)
* [Room for Improvement](#room-for-improvement)
* [Contact](#contact)
<!-- * [License](#license) -->


## General Information
- Build a CNN Model for hand gestures image classification using TensorFlow with Keras. Use djitellopy to access the drone
in order to apply the model.
- Move the drone up, down, left, right using hand gestures and pc camera.
- Fun way to explore machine learning.


## Technologies Used
- Python 3
- Tensorflow 2 with Keras
- djitellopy
- Numpy
- OpenCV (cv2)
- PyPlot (for plotting results)


## Features
- CNN Model for image classification.
- Move drone up, down, left, right.

## Setup
Everything is run on Jupyter Notebook. Could be done on google colab as well.
Link for Jupyter Notebook: https://jupyter.org/

## Project Status
Project is: complete (features can be added).


## Room for Improvement

Room for improvement:
- Add more hand gestures.
- Add more moving functionality.

## Contact
panagiotis.michael133@gmail.com - feel free to contact me!
